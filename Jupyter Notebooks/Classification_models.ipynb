{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "851b4283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2903225806451613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "directory = \"../data\"\n",
    "file = directory + \"/gen1_pokemon_stats.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Separate the features (predictors) and the target variable\n",
    "X = df.drop(['type_1', 'type_2', 'Pokemon'], axis=1)\n",
    "y = df['type_1']\n",
    "\n",
    "# Perform one-hot encoding on the \"type_1\" column\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X_encoded = ct.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c92e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9631cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [ 6.78216911  7.08461347  7.24405489  7.34922868  7.41349425  7.50205895\n  7.56129089  7.67799502  7.81506582  7.89106802  7.92330413  7.93048985\n  7.98238946  8.018025    8.12714643  8.18135554  8.29422901  8.48705649\n  8.51388181  8.9576105   9.03960557  9.05923765  9.10881466  9.11275876\n  9.24914832  9.46832363  9.48685322  9.58620407 10.10282242 10.19546429\n 10.25760111]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m ridge_y_pred \u001b[38;5;241m=\u001b[39m ridge_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Inverse transform the encoded predictions to get the original string labels\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m lasso_y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlasso_y_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m ridge_y_pred \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(ridge_y_pred)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Evaluate the performance of the models\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:162\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(y, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)))\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff):\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(diff))\n\u001b[0;32m    163\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[y]\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [ 6.78216911  7.08461347  7.24405489  7.34922868  7.41349425  7.50205895\n  7.56129089  7.67799502  7.81506582  7.89106802  7.92330413  7.93048985\n  7.98238946  8.018025    8.12714643  8.18135554  8.29422901  8.48705649\n  8.51388181  8.9576105   9.03960557  9.05923765  9.10881466  9.11275876\n  9.24914832  9.46832363  9.48685322  9.58620407 10.10282242 10.19546429\n 10.25760111]"
     ]
    }
   ],
   "source": [
    "#using the ridge and lasso complained because my models columns are continuous. it is either a value of 1, 2 or 3. That algorith did\n",
    "#was not compatible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab989748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03225806451612903\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "directory = \"../data\"\n",
    "file = directory + \"/gen1_pokemon_stats.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Separate the features (predictors) and the target variable\n",
    "X = df.drop(['type_1', 'type_2', 'Pokemon'], axis=1)\n",
    "y = df['type_1']\n",
    "\n",
    "# Perform one-hot encoding on the \"type_1\" column\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X_encoded = ct.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4cb1ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16129032258064516\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "directory = \"../data\"\n",
    "file = directory + \"/gen1_pokemon_stats.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Separate the features (predictors) and the target variable\n",
    "X = df.drop(['type_1', 'type_2', 'Pokemon'], axis=1)\n",
    "y = df['type_1']\n",
    "\n",
    "# Perform one-hot encoding on the \"type_1\" column\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X_encoded = ct.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a random forest classifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b366f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12903225806451613\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "directory = \"../data\"\n",
    "file = directory + \"/gen1_pokemon_stats.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Separate the features (predictors) and the target variable\n",
    "X = df.drop(['type_1', 'type_2', 'Pokemon'], axis=1)\n",
    "y = df['type_1']\n",
    "\n",
    "# Perform one-hot encoding on the \"type_1\" column\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X_encoded = ct.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train an SVM classifier\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d940fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
